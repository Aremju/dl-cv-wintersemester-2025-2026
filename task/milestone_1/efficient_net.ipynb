{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9dc954-ed69-495f-88bc-a4670e801bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "data dir:  ../../data/animal_images ,  num epochs:  5 ,  batch size:  8 , img size:  [1024, 1024] , num of classes: 15 .pth weights file location: None , learning rate: 0.01 , net name: efficientnet-b3 epoch to resume from:  0 momen\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Data Size {'train': 30003, 'test': 2409}\n",
      "Epoch 0/4\n",
      "----------\n",
      "LR is set to 0.01\n",
      "tensor([[ 7.5676e-02,  1.6171e-01,  9.6510e-02,  1.0545e-01, -3.0375e-02,\n",
      "         -9.5809e-02, -1.6430e-01, -1.0962e-01,  1.2934e-01, -8.4826e-02,\n",
      "         -6.1713e-02, -6.0095e-02,  5.9747e-02,  8.1412e-02,  1.5078e-02],\n",
      "        [ 2.1081e-01,  9.9202e-03, -6.7398e-02,  9.0714e-02, -6.9871e-02,\n",
      "         -1.4718e-01,  5.0284e-02, -2.0373e-01, -1.1223e-01,  2.2592e-01,\n",
      "          4.6539e-02, -4.5764e-02,  2.4755e-02, -6.0636e-02, -5.5904e-02],\n",
      "        [ 1.0743e-01,  1.6417e-01, -1.1751e-03, -6.5207e-02, -3.3134e-02,\n",
      "         -2.3527e-01, -1.1317e-01, -5.4109e-03, -5.9129e-02,  5.6145e-02,\n",
      "         -2.5099e-01, -1.1884e-01,  2.2448e-01, -1.2197e-01, -2.2098e-01],\n",
      "        [-1.6274e-02,  1.2329e-01,  7.6110e-03,  1.1883e-02,  1.2944e-02,\n",
      "         -9.9316e-02, -4.7613e-02, -1.1810e-03, -1.4367e-01, -2.8054e-04,\n",
      "         -9.4245e-02, -5.4322e-02,  4.8983e-02,  7.6141e-02,  5.3281e-02],\n",
      "        [ 5.9947e-02, -6.2452e-02, -8.3368e-02,  1.1469e-01, -9.2328e-02,\n",
      "         -7.6434e-02,  2.0675e-02, -1.1171e-01, -7.5149e-02, -4.8579e-02,\n",
      "         -2.0613e-01, -1.5091e-01,  1.6792e-01,  6.4604e-02,  7.6876e-02],\n",
      "        [ 1.6194e-01, -1.5301e-01,  9.1116e-02, -3.9769e-02, -1.3686e-01,\n",
      "         -1.1231e-01,  7.7782e-02, -1.1092e-01,  2.4599e-02, -3.4727e-02,\n",
      "         -8.3456e-02, -8.3388e-02,  1.6464e-01,  3.5512e-02,  5.0988e-02],\n",
      "        [ 3.4669e-02, -4.9500e-02, -4.6167e-02, -6.4994e-02,  2.3916e-02,\n",
      "         -6.9437e-02,  6.6325e-03, -5.6996e-03,  5.7849e-02, -1.8847e-02,\n",
      "         -9.7477e-02,  4.4354e-02,  1.2614e-01,  1.2164e-01,  4.2539e-02],\n",
      "        [ 1.5621e-01,  3.8489e-01, -6.5034e-02, -1.6906e-01, -2.2628e-02,\n",
      "         -6.5416e-02,  2.4595e-01, -2.5563e-01, -3.2469e-02, -2.8762e-02,\n",
      "         -1.3631e-01, -2.5772e-01,  1.0333e-01,  3.9103e-02, -4.6421e-02]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([ 6, 13,  9, 13,  1, 10,  6,  2], device='cuda:0')\n",
      "Epoch:0: loss:2.602\n",
      "Epoch:0: loss:2.131\n",
      "Epoch:0: loss:2.084\n",
      "Epoch:0: loss:1.343\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from efficientnet_pytorch.model import EfficientNet\n",
    "\n",
    "import argparse\n",
    "\n",
    "# some parameters\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print(use_gpu)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "data_dir = ''\n",
    "num_epochs = 5\n",
    "batch_size = 4\n",
    "input_size = 4\n",
    "class_num = 3\n",
    "weights_loc = \"\"\n",
    "lr = 0.01\n",
    "net_name = 'efficientnet-b3'\n",
    "epoch_to_resume_from = 0\n",
    "momentum = 0.9\n",
    "\n",
    "\n",
    "def loaddata(data_dir, batch_size, set_name, shuffle):\n",
    "    if set_name.lower() in [\"train\", \"training\", \"training data\"]:\n",
    "        folder = os.path.join(data_dir, \"Training Data\", \"Training Data\")\n",
    "    elif set_name.lower() in [\"val\", \"validation\", \"validation data\"]:\n",
    "        folder = os.path.join(data_dir, \"Validation Data\", \"Validation Data\")\n",
    "    elif set_name.lower() in [\"test\", \"testing\", \"test\", \"Testing Data\"]:\n",
    "        folder = os.path.join(data_dir, \"Testing Data\", \"Testing Data\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown set_name: {set_name}\")\n",
    "    \n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                 [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                 [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                 [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    image_datasets = {\n",
    "        'train': datasets.ImageFolder(os.path.join(data_dir, \"Training Data\", \"Training Data\"), transform=data_transforms['train']),\n",
    "        'val':  datasets.ImageFolder(os.path.join(data_dir, \"Validation Data\", \"Validation Data\"), transform=data_transforms['val']),\n",
    "        'test':  datasets.ImageFolder(os.path.join(data_dir, \"Testing Data\", \"Testing Data\"), transform=data_transforms['test'])\n",
    "    }\n",
    "\n",
    "    dataloaders = {\n",
    "        x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=(x=='train'), num_workers=0)\n",
    "        for x in ['train', 'val', 'test']\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "\n",
    "    return dataloaders, dataset_sizes\n",
    "\n",
    "\n",
    "def train_model(model_ft, criterion, optimizer, lr_scheduler, num_epochs=5):\n",
    "\n",
    "    train_loss = []\n",
    "    since = time.time()\n",
    "    best_model_wts = model_ft.state_dict()\n",
    "    best_acc = 0.0\n",
    "    model_ft.train(True)\n",
    "\n",
    "    for epoch in range(epoch_to_resume_from, num_epochs):\n",
    "\n",
    "        dset_loaders, dset_sizes = loaddata(data_dir=data_dir, batch_size=batch_size, set_name='train', shuffle=True)\n",
    "        print('Data Size', dset_sizes)\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        optimizer = lr_scheduler(optimizer, epoch)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        count = 0\n",
    "\n",
    "        for data in dset_loaders['train']:\n",
    "            inputs, labels = data\n",
    "            labels = torch.squeeze(labels.type(torch.LongTensor))\n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            outputs = model_ft(inputs)\n",
    "            \n",
    "            if count % 500 == 0:\n",
    "                print(outputs)\n",
    "                print(labels)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            count += 1\n",
    "            if count % 30 == 0 or outputs.size()[0] < batch_size:\n",
    "                print('Epoch:{}: loss:{:.3f}'.format(epoch, loss.item()))\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / dset_sizes\n",
    "        epoch_acc = running_corrects.double() / dset_sizes\n",
    "\n",
    "        print('Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            epoch_loss, epoch_acc))\n",
    "\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = model_ft.state_dict()\n",
    "        if epoch_acc > 0.999:\n",
    "            break\n",
    "\n",
    "    # save best model\n",
    "    save_dir = data_dir + '/model'\n",
    "    model_ft.load_state_dict(best_model_wts)\n",
    "    model_out_path = save_dir + \"/\" + net_name + '.pth'\n",
    "    torch.save(model_ft, model_out_path)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return train_loss, best_model_wts\n",
    "\n",
    "\n",
    "def test_model(model, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    cont = 0\n",
    "    outPre = []\n",
    "    outLabel = []\n",
    "    dset_loaders, dset_sizes = loaddata(data_dir=data_dir, batch_size=batch_size, set_name='test', shuffle=False)\n",
    "    for data in dset_loaders['test']:\n",
    "        inputs, labels = data\n",
    "        labels = torch.squeeze(labels.type(torch.LongTensor))\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        if cont == 0:\n",
    "            outPre = outputs.data.cpu()\n",
    "            outLabel = labels.data.cpu()\n",
    "        else:\n",
    "            outPre = torch.cat((outPre, outputs.data.cpu()), 0)\n",
    "            outLabel = torch.cat((outLabel, labels.data.cpu()), 0)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        cont += 1\n",
    "    print('Loss: {:.4f} Acc: {:.4f}'.format(running_loss / dset_sizes,\n",
    "                                            running_corrects.double() / dset_sizes))\n",
    "\n",
    "\n",
    "def exp_lr_scheduler(optimizer, epoch, init_lr=0.01, lr_decay_epoch=10):\n",
    "    \"\"\"Decay learning rate by a f#            model_out_path =\"./model/W_epoch_{}.pth\".format(epoch)\n",
    "#            torch.save(model_W, model_out_path) actor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (0.8**(epoch // lr_decay_epoch))\n",
    "    print('LR is set to {}'.format(lr))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def run():\n",
    "    # train\n",
    "    pth_map = {\n",
    "        'efficientnet-b0': 'efficientnet-b0-355c32eb.pth',\n",
    "        'efficientnet-b1': 'efficientnet-b1-f1951068.pth',\n",
    "        'efficientnet-b2': 'efficientnet-b2-8bb594d6.pth',\n",
    "        'efficientnet-b3': 'efficientnet-b3-5fb5a3c3.pth',\n",
    "        'efficientnet-b4': 'efficientnet-b4-6ed6700e.pth',\n",
    "        'efficientnet-b5': 'efficientnet-b5-b6417697.pth',\n",
    "        'efficientnet-b6': 'efficientnet-b6-c76e70fd.pth',\n",
    "        'efficientnet-b7': 'efficientnet-b7-dcc49843.pth',\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    if weights_loc != None:\n",
    "        model_ft = torch.load(weights_loc)\n",
    "    else:\n",
    "        model_ft = EfficientNet.from_pretrained(net_name)\n",
    "\n",
    "\n",
    "    # Modify the fully connected layer\n",
    "    num_ftrs = model_ft._fc.in_features\n",
    "    model_ft._fc = nn.Linear(num_ftrs, class_num)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if use_gpu:\n",
    "        model_ft = model_ft.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    optimizer = optim.SGD((model_ft.parameters()), lr=lr,\n",
    "                        momentum=momentum, weight_decay=0.0004)\n",
    "\n",
    "    train_loss, best_model_wts = train_model(model_ft, criterion, optimizer, exp_lr_scheduler, num_epochs=num_epochs)\n",
    "\n",
    "    # test\n",
    "    print('-' * 10)\n",
    "    print('Test Accuracy:')\n",
    "\n",
    "    model_ft.load_state_dict(best_model_wts)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    test_model(model_ft, criterion)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    if \"ipykernel_launcher\" in sys.argv[0]:\n",
    "        sys.argv = ['']\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--data-dir', type=str, default=\"../../data/animal_images\", help='path of /dataset/')\n",
    "    parser.add_argument('--num-epochs', type=int, default=5)\n",
    "    parser.add_argument('--batch-size', type=int, default=8, help='total batch size for all GPUs')\n",
    "    parser.add_argument('--img-size', type=int, default=[1024, 1024], help='img sizes')\n",
    "    parser.add_argument('--class-num', type=int, default=15, help='class num')\n",
    "\n",
    "    parser.add_argument('--weights-loc', type=str, default= None, help='path of weights (if going to be loaded)')\n",
    "\n",
    "    parser.add_argument(\"--lr\", type=float, default= 0.01, help=\"learning rate\")\n",
    "    parser.add_argument(\"--net-name\", type=str, default=\"efficientnet-b3\", help=\"efficientnet type\")\n",
    "\n",
    "    parser.add_argument('--resume-epoch', type=int, default=0, help='what epoch to start from')\n",
    "\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
    "\n",
    "\n",
    "\n",
    "    opt = parser.parse_args()\n",
    "\n",
    "    data_dir = opt.data_dir\n",
    "    num_epochs = opt.num_epochs\n",
    "    batch_size = opt.batch_size\n",
    "    input_size = opt.img_size\n",
    "    class_num = opt.class_num\n",
    "\n",
    "    weights_loc = opt.weights_loc\n",
    "\n",
    "    lr = opt.lr\n",
    "    net_name = opt.net_name\n",
    "\n",
    "    epoch_to_resume_from = opt.resume_epoch\n",
    "\n",
    "    momentum = opt.momentum\n",
    "\n",
    "    print(\"data dir: \", data_dir, \",  num epochs: \", num_epochs, \",  batch size: \",batch_size,\n",
    "             \", img size: \", input_size, \", num of classes:\", class_num, \".pth weights file location:\", weights_loc,\n",
    "             \", learning rate:\", lr, \", net name:\", net_name, \"epoch to resume from: \", epoch_to_resume_from, \"momen\")\n",
    "\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69429633-9e1b-49a5-ae3c-e8524ba39bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
