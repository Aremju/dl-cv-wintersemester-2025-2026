{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65ad528b-3221-42ee-9400-b6586f9e22a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 14:40:41.176425: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-16 14:40:41.241178: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-12-16 14:40:42.282368: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import TFViTForImageClassification, ViTConfig, ViTImageProcessor, Trainer, TrainingArguments\n",
    "from torchvision.transforms import v2\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf2dc5-3ae8-456c-b9ef-fcd504359c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "animal_dataset = load_dataset(\"imagefolder\", data_dir=\"../../../data/animal_images\")\n",
    "animal_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66161a9c-e2b0-4355-b320-54bce6fdeadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking example structure of dataset in training data\n",
    "features = animal_dataset[\"train\"].features\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe0fff1-24e9-4a57-aeac-d71d48498c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of example content of dataset\n",
    "animal_dataset['train'][10]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dc431e-0845-4b8c-98d0-77ec7fd5d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into seperate datasets to parse onto trainer later on\n",
    "train_data = animal_dataset[\"train\"]\n",
    "validation_data = animal_dataset[\"validation\"]\n",
    "test_data = animal_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7116a53-c51a-4ecf-b64d-aaf190172eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mapping for model (label-name -> index)\n",
    "id2label = {id: label for id, label in enumerate(train_data.features[\"label\"].names)}\n",
    "label2id = {label: id for id, label in id2label.items()}\n",
    "id2label, id2label[train_data[0][\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218f636b-d58f-49b0-acfd-6bbba9bfd9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading processor\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224', do_rescale = False, return_tensors = 'pt')\n",
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eebd5e1-a901-4d00-91cb-2250d0b6f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms \n",
    "\n",
    "# Get configurations from ViT processor\n",
    "size = processor.size.get(\"height\", 224)\n",
    "image_mean, image_std = processor.image_mean, processor.image_std\n",
    "\n",
    "# Normalization and augmentation transformations\n",
    "transformations = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomResizedCrop(size),\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3),\n",
    "        transforms.Resize(size),\n",
    "        transforms.CenterCrop(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=image_mean, std=image_std),\n",
    "    ]),\n",
    "    \"validation\": transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.CenterCrop(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=image_mean, std=image_std),\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.CenterCrop(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=image_mean, std=image_std),\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90ddc24-ad8a-4a99-8e5c-2750d8192df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the specified transformation configuration and apply it to the given example for \n",
    "def transform(examples, kind=\"train\"):\n",
    "    transform_fn = transformations.get(kind, transformations[\"train\"])\n",
    "    examples[\"pixel_values\"] = [transform_fn(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    return examples\n",
    "    \n",
    "# Attaching right transformations to each dataset\n",
    "train_data.set_transform(lambda examples: transform(examples, \"train\"))\n",
    "validation_data.set_transform(lambda examples: transform(examples, \"validation\"))\n",
    "test_data.set_transform(lambda examples: transform(examples, \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59635f12-a689-46e9-8f85-27d59fe24878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Function fixes issue with data-types, as default trainer collate function is not aware how to stack the tensors from our dataset\n",
    "def collate_fn(examples):\n",
    "    # Stacks the pixel values of all examples into a single tensor and collects labels into a tensor\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels, \"interpolate_pos_encoding\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee559da-0255-4b70-92e6-24dfa05ec5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model loading\n",
    "import tensorflow as tf\n",
    "from transformers import ViTForImageClassification, ViTConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import types\n",
    "\n",
    "labels = animal_dataset['train'].features['label'].names\n",
    "BASE_MODEL_CONF = \"google/vit-base-patch16-224\"\n",
    "\n",
    "PATCH_SIZE = 16\n",
    "LAMBDA_H = -0.3\n",
    "\n",
    "# Label mapping and patch size are defined in config\n",
    "config = ViTConfig.from_pretrained(BASE_MODEL_CONF)\n",
    "config.patch_size = PATCH_SIZE\n",
    "config.num_labels = len(labels)\n",
    "config.id2label = id2label\n",
    "config.label2id = label2id\n",
    "\n",
    "# Eager attention implementation to access attention outputs in model\n",
    "config._attn_implementation = \"eager\"\n",
    "\n",
    "# Loading model with proper label mapping + configurable patch size\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    BASE_MODEL_CONF,\n",
    "    config=config,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b31dba7-a6d3-48f3-a56f-dabe8ce23644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# Training params\n",
    "TRAINING_STRATEGY = \"fixed\"\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "STEPS = 200\n",
    "\n",
    "output_dir = f\"results_entropy_scaling/output_vit_attention_mechanism_entropy_{LAMBDA_H}_scaling\"\n",
    "\n",
    "train_configs = {\n",
    "    \"fixed\": TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_steps=1,\n",
    "        eval_steps=1,\n",
    "        # warmup_steps=STEPS, \n",
    "        num_train_epochs=EPOCHS,\n",
    "        fp16=True,\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=STEPS,\n",
    "        learning_rate=2e-4,\n",
    "        # optim=\"adamw_torch\",\n",
    "        remove_unused_columns=False,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        load_best_model_at_end=True,\n",
    "        greater_is_better=True,\n",
    "        report_to=\"tensorboard\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=3,\n",
    "        seed = 123\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3671da-5f0c-4997-88cf-19af79dbf4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Load standard evaluation metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "\n",
    "# Function called after completing eval strategy rule\n",
    "def compute_metrics(eval_pred):\n",
    "    # Accessing model predictions\n",
    "    preds = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "\n",
    "    # Now receiving tuple because output_attentions = True\n",
    "    if isinstance(preds, (tuple, list)):\n",
    "        preds = preds[0]  # logits\n",
    "    # Takes the model output with the highest value (so the most likely class to be predicted)\n",
    "    pred_ids = np.argmax(preds, axis=-1)\n",
    "\n",
    "    # Computing all predefined metrics\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=pred_ids, references=labels)[\"accuracy\"],\n",
    "        \"precision\": precision.compute(predictions=pred_ids, references=labels, average=\"weighted\")[\"precision\"],\n",
    "        \"recall\": recall.compute(predictions=pred_ids, references=labels, average=\"weighted\")[\"recall\"],\n",
    "        \"f1\": f1.compute(predictions=pred_ids, references=labels, average=\"weighted\")[\"f1\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0936d309-ce74-4a46-8aed-f183b4322134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import Trainer\n",
    "\n",
    "class EntropyScalingTrainer(Trainer):\n",
    "    # Scaling parameter\n",
    "    LAMBDA_ENTROPY = LAMBDA_H\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # print(self.LAMBDA_ENTROPY)\n",
    "        # Information from standard forward\n",
    "        outputs = model(**inputs)\n",
    "        # Cross-Entropy is used for loss calculation\n",
    "        loss = outputs.loss\n",
    "\n",
    "        logits = outputs.logits\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        probs = log_probs.exp()\n",
    "\n",
    "        # Shannon-Entropy: H(p) = -sum p log p\n",
    "        entropy = -(probs * log_probs).sum(dim=-1)\n",
    "\n",
    "        entropy_mean = entropy.mean()\n",
    "\n",
    "        # Entropy for loss:\n",
    "        # if lambda > 0 : loss = loss - λ * H\n",
    "        # if lambda < 0: loss = loss + λ * H\n",
    "        loss = loss - self.LAMBDA_ENTROPY * entropy_mean\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b632017f-c77c-4f97-acfa-73e5bf0f81e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model always return attentions\n",
    "# model.config.output_attentions = True\n",
    "# model.config.return_dict = True\n",
    "\n",
    "# Initializes trainer with custom entropy loss regularization\n",
    "trainer = EntropyScalingTrainer(\n",
    "    model=model,\n",
    "    args=train_configs.get(TRAINING_STRATEGY),\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=validation_data,\n",
    "    data_collator=collate_fn,\n",
    "    tokenizer=processor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.001)],\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d922da5-af95-4398-a9ed-3f6955066fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Evaluation of model\n",
    "predictions = trainer.predict(test_data)\n",
    "\n",
    "# Ids of True Labels\n",
    "labels_true = predictions.label_ids\n",
    "# Ids of predicted labels\n",
    "labels_pred = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "# Configs for label <-> id mapping\n",
    "id2label = model.config.id2label\n",
    "label2id = model.config.label2id\n",
    "\n",
    "# Plot of confusion matrix\n",
    "result_confusion = confusion_matrix(labels_true, labels_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=result_confusion, display_labels=labels)\n",
    "disp.plot(cmap=\"Blues\", xticks_rotation=70, values_format=\"d\", ax=ax)\n",
    "\n",
    "ax.set_xlabel(\"Predicted Labels\", fontsize=15, labelpad=15)\n",
    "ax.set_ylabel(\"True Labels\", fontsize=15, labelpad=15)\n",
    "ax.set_title(\"Confusion Matrix (Animal_Images)\", fontsize=16, pad=10)\n",
    "\n",
    "ax.tick_params(axis=\"x\", labelsize=11, pad=5)\n",
    "ax.tick_params(axis=\"y\", labelsize=11, pad=5)\n",
    "plt.tight_layout()\n",
    "\n",
    "output_path = f\"{output_dir}/confusion_matrix.png\"\n",
    "plt.savefig(output_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Output of sklearn classification report\n",
    "report = classification_report(\n",
    "    labels_true,\n",
    "    labels_pred,\n",
    "    target_names=labels,\n",
    "    output_dict=True,\n",
    ")\n",
    "\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "print(f\"\\n\\n scikit-learn report: \\n{report_df}\")\n",
    "\n",
    "report_df.to_csv(f\"{output_dir}/classification_report.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc0ef6c-34fe-41b2-b09b-92afda424873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2214d33b-a3ae-479d-856e-f34e251faaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ccce1-ed22-4228-84b8-fac39d938090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
